# -*- coding: utf-8 -*-
"""AI_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NVZX_y-mxaMyagyGf9aJzO_cbsk1lQho
"""

!pip install transformers timm spotipy accelerate -q

from PIL import Image
import io
from google.colab import files

uploaded = files.upload()
image_path = next(iter(uploaded))
image = Image.open(io.BytesIO(uploaded[image_path])).convert("RGB")
image.show()

from transformers import BlipProcessor, BlipForConditionalGeneration

processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

inputs = processor(images=image, return_tensors="pt")
out = model.generate(**inputs)
caption = processor.decode(out[0], skip_special_tokens=True)

print("🧠 BLIP Caption:", caption)

from transformers import pipeline

theme_generator = pipeline("text-generation", model="distilgpt2")

theme_prompt = f"Music mood for image description: {caption}\nMood:"
theme_result = theme_generator(theme_prompt, max_new_tokens=20, do_sample=True, top_k=50)[0]["generated_text"]

# Clean up
theme_keywords = theme_result.replace(theme_prompt, "").strip().split("\n")[0]
print("🎼 Inferred Song Theme:", theme_keywords)

from spotipy.oauth2 import SpotifyClientCredentials
import spotipy
import os

# 🔐 Set your Spotify credentials (create app at https://developer.spotify.com/dashboard/)
os.environ['SPOTIPY_CLIENT_ID'] = '1dcc31fe1856414bb5f6166002009a60'
os.environ['SPOTIPY_CLIENT_SECRET'] = 'e006ba5dd99c44f2994aafd0a62bb8e6'

auth_manager = SpotifyClientCredentials()
sp = spotipy.Spotify(auth_manager=auth_manager)

# Build queries per language
languages = {
    "Telugu": theme_keywords + " telugu",
    "Hindi": theme_keywords + " hindi",
    "English": theme_keywords + " english",
    "Tamil": theme_keywords + " tamil"
}

print("🎶 Recommended Songs Based on Inferred Mood:")

for lang, query in languages.items():
    results = sp.search(q=query + " music", limit=1, type='track')
    if results['tracks']['items']:
        track = results['tracks']['items'][0]
        print(f"🎵 {lang}: {track['name']} by {track['artists'][0]['name']}")
        print(track['external_urls']['spotify'])
        print()
    else:
        print(f"❌ No {lang} song found for: {query}")

def format_instagram_caption_from_blip(blip_caption):
    emoji_map = {
        "flower": "🌸", "garden": "🌿", "tree": "🌳", "sunset": "🌇",
        "beach": "🏖️", "mountain": "⛰️", "sky": "☁️", "dog": "🐶",
        "cat": "🐱", "bird": "🐦", "car": "🚗", "bike": "🏍️",
        "lake": "🏞️", "river": "🌊", "people": "🧍‍♂️", "building": "🏛️",
        "road": "🛣️", "city": "🌆", "sunrise": "🌄", "bicycle": "🚲", "child": "🧒"
    }

    emojis = " ".join([v for k, v in emoji_map.items() if k in blip_caption.lower()])
    insta_caption = f"{blip_caption.capitalize()}. {emojis}"

    keywords = blip_caption.lower().split()
    hashtags = "#" + " #".join([word for word in keywords if word.isalpha() and len(word) > 3])

    return insta_caption, hashtags

insta_caption, insta_hashtags = format_instagram_caption_from_blip(caption)

print("📸 Instagram Caption:")
print(insta_caption)

print("\n🏷️ Hashtags:")
print(insta_hashtags)

def generate_image_quote_from_caption(blip_caption):
    caption = blip_caption.lower()

    if any(word in caption for word in ["flower", "garden", "bloom", "nature", "tree"]):
        return "Let yourself bloom like the flowers — quietly and beautifully."
    elif any(word in caption for word in ["sunset", "sunrise", "sky", "cloud"]):
        return "Every sunset brings the promise of a new dawn."
    elif any(word in caption for word in ["beach", "sea", "ocean", "waves"]):
        return "The cure for anything is saltwater — sweat, tears, or the sea."
    elif any(word in caption for word in ["mountain", "hill", "peak"]):
        return "The best views come after the hardest climbs."
    elif any(word in caption for word in ["road", "journey", "car", "bike", "ride"]):
        return "The journey is the destination."
    elif any(word in caption for word in ["rain", "cloudy", "storm", "umbrella"]):
        return "Rain is just confetti from the sky."
    elif any(word in caption for word in ["child", "children", "smile"]):
        return "Every child is a different kind of flower, and all together they make this world a beautiful garden."
    elif any(word in caption for word in ["city", "street", "people", "crowd"]):
        return "In the middle of the noise, find your own melody."
    else:
        return "Every picture tells a story — make yours worth sharing."

image_quote = generate_image_quote_from_caption(caption)
print("💬 Inspirational Quote:\n", image_quote)

print("🎯 Final SnapTune Results\n")
print("🖼️ Image Caption:\n", caption)
print("\n🎧 Music Mood:\n", theme_keywords)
print("\n📸 Instagram Caption:\n", insta_caption)
print("\n🏷️ Hashtags:\n", insta_hashtags)
print("\n💬 Inspirational Quote:\n", image_quote)

with open("snaptune_output.txt", "w") as f:
    f.write(f"📸 Instagram Caption:\n{insta_caption}\n\n")
    f.write(f"🏷️ Hashtags:\n{insta_hashtags}\n\n")
    f.write(f"💬 Quote:\n{image_quote}\n")
print("📁 Saved to snaptune_output.txt")